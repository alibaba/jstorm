---
title:  "How to create/remove/enlarge/reduce one JStorm logic cluster?"
# Top-level navigation
top-nav-group: Maintenance
top-nav-pos: 5
top-nav-title: JStorm-on-Yarn 
---

* This will be replaced by the TOC
{:toc}

# function points
Currently support cluster management through script invokes the thrift interface.
The invoke path is bin/JstormYarn

## Create a cluster
* Create a cluster, limit the number of cluster resources (cpu core and memory)
* Each cluster can support different versions of jstorm and jdk 
* Multiple logical cluster container can run on one machine
* Start: Executive submitJstormOnYarn command to submit a cluster, then start nimbus and supervisor with the startNimbus and addSupervisors command

## Destroy a cluster
* execute killJstormOnYarn, kill the process

## Upgrading a cluster binary
* Update jstorm deployment files under deploy directory
* Execute upgradeCluster command

## Upgrading a cluster configuration
* Update storm.yaml under deploy/jstorm/conf 
* Execute upgradeCluster command

## Download binary and configuration file of a cluster
* The configuration item jstorm.yarn.instance.deploy.dir is the storage path of current binary files on hadoop

## Restart Cluster
* Execute upgradeCluster command

## View cluster status
* Execute list command

## Expand and reduce the capacity of cluster
* Execute Command addSupervisors and removeSupervisors

# JStorm-on-Yarn Process
Unlike spark-on-yarn that an AM is generated each time when submitting an application to cluster. The AM of jstorm-on-yarn is permanent, that is, for a JStorm cluster, it will be only one AM.


This is mainly determined by the scheduling of JStorm: JStorm currently have TopologyMaster, as the arbiter of the topology. 
According to the design of YARN, the ideal way should be let TopologyMaster be AM, to coordinate the operation of a particular topology, 
including the allocation of worker, tracking heartbeat of task. However, since the TopologyMaster has been formed 
and on top of it, metrics, heartbeat, back pressure will go through TM. That makes the cost will be very expensive if we make such modification, it may lead to the change in the entire JStorm architecture, more harm than good.

So currently jstorm-on-yarn works as that there is an AM as total control. It is responsible for the following tasks:
* Create Nimbus (and automatically restart nimbus when it hung)
* Receives requests and create Supervisor 
* Cluster capacity expand and reduce dynamically

Submitting, killing and other operations on the topology, interact with nimbus and supervisor in the container directly as with the standalone cluster of JStorm, do not interact with AM.

## Create AM
From start-JstormYarn.sh start, it will call JStormOnYarn class to create AM, essentially the yarn client of JStorm.
This class is quite simple, it mainly set some parameters of nimbus container, such as memory, CPU core, jar, libjar, shellscript (actual value is start_jstorm.sh, for starting nimbus and supervisor).
Then uploaded the jar and shellscript to the HDFS. Finally call `yarnClient.submitApplication (appContext)` to create the AM.

## Creating nimbus and supervisor
This step is achieved through thrift interface, embodied as: client end JstormAM.py (automatically generated by thrift), server-side automatically generated RPC interface is JstormAM, while the real processing logic is in JstormAMHandler class (the same as the thrift in jstorm). The handler initializes thrift server and monitor client's requests when it creates AM.

Look at a few important methods: addSupervisors and startNimbus
In fact, these two methods have similar implements. In essence, it specified the number of container, CPU core count. Launching the supervisor or nimbus is done in JStormMaster. It determine to launch the supervisor or nimbus base on the container's priority property.

Note that, when jstorm-on-yarn creates a supervisor, not only apply the memory for supervisor itself, but will specify a chunk of memory (such as 20 or 40G), the container will hold all the worker under the supervisor. When the container is hung due to some question , all the workers will be killed, which is more stringent than in the standalone cluster.

# Maintenance and configuration instructions

## Jstorm Configuration

In order to facilitate the maintenance, please add the following configuration at all storm.yaml in YARN cluster:

```
 jstorm.on.yarn: true
 supervisor.childopts:  -Djstorm-on-yarn=true
 jstorm.log.dir: /home/yarn/jstorm_logs/<cluster_name>
```

The above configuration will override the default log path, all the logs are redirected to the /home/yarn below, preventing from missing the log after the container hangs. If more than one container of supervisor is launch on the same machine, it will add value `supervisor.deamon.logview.port` at the end of supervisor log (YARN dynamically generated port and port range for each container) to distinguish logs and prevent the logs from affecting each other. For example if two supervisor http ports are 9000 and 9001 respectively, then supervisor-9000.log and supervisor-9001.log are generated. koala will add the specified port suffix for the log according to the `jstorm.on.yarn` configuration.

## Yarn Configuration

TO BE ADDED

# Yarn introductory series articles 

See: http: //zh.hortonworks.com/get-started/yarn/